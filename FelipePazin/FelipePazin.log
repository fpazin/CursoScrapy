2019-04-24 17:34:10 [scrapy.extensions.telnet] INFO: Telnet Password: 5a59011637a11ac8
2019-04-24 17:34:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2019-04-24 17:34:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-24 17:34:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-24 17:34:11 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-24 17:34:11 [scrapy.core.engine] INFO: Spider opened
2019-04-24 17:34:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-24 17:34:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-24 17:34:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-24 17:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental> (referer: None)
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental)
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental>
{'autor': None, 'data': None, 'div': None}
2019-04-24 17:34:13 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://repositorio.ufpa.br/jspui/simple-search?query=sa%C3%BAde+mental> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2019-04-24 17:34:13 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-24 17:34:13 [scrapy.extensions.feedexport] INFO: Stored csv feed (22 items) in: FelipePazin_Resultado.csv
2019-04-24 17:34:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 884,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 25131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 24, 20, 34, 13, 376132),
 'item_scraped_count': 22,
 'log_count/DEBUG': 26,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/disk': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/disk': 2,
 'start_time': datetime.datetime(2019, 4, 24, 20, 34, 11, 311165)}
2019-04-24 17:34:13 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:01:43 [scrapy.extensions.telnet] INFO: Telnet Password: 67be57dc79e7381b
2019-04-29 23:01:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2019-04-29 23:01:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:01:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:01:44 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:01:44 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:01:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:01:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:01:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:01:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:01:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 22, in parse
    for link in links:
NameError: name 'links' is not defined
2019-04-29 23:01:45 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:01:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 484,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 1, 45, 720154),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/disk': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/disk': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 1, 44, 211110)}
2019-04-29 23:01:45 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:03:20 [scrapy.extensions.telnet] INFO: Telnet Password: a454785931d3625f
2019-04-29 23:03:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:03:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:03:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:03:20 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:03:20 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:03:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:03:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:03:23 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:03:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 22, in parse
    for link in links:
NameError: name 'links' is not defined
2019-04-29 23:03:24 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:03:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 484,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 3, 24, 714168),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 3, 20, 642110)}
2019-04-29 23:03:24 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:03:45 [scrapy.extensions.telnet] INFO: Telnet Password: f957c3094596a62a
2019-04-29 23:03:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:03:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:03:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:03:45 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:03:45 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:03:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:03:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:03:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:03:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 23, in parse
    url_artigo = link.css('a').attrib['haref']
KeyError: 'haref'
2019-04-29 23:03:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:03:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 484,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 12823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 3, 46, 848157),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 3, 45, 960153)}
2019-04-29 23:03:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:04:00 [scrapy.extensions.telnet] INFO: Telnet Password: 738b55cfe510481b
2019-04-29 23:04:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:04:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:04:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:04:00 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:04:00 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:04:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:04:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:04:00 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:04:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:04:01 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET :///robots.txt>: Unsupported URL scheme '': no handler available for that scheme
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/7326>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/10279>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/5359>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/5841>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/7476>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/6939>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/3276>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/10076>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/10334>
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:01 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/7208>
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:04:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:04:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 11,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 11,
 'downloader/request_bytes': 4049,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 12823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 4, 2, 90114),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 "robotstxt/exception_count/<class 'scrapy.exceptions.NotSupported'>": 1,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 4, 0, 574110)}
2019-04-29 23:04:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:07:02 [scrapy.extensions.telnet] INFO: Telnet Password: e80b721b1fb16d2a
2019-04-29 23:07:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:07:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:07:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:07:02 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:07:02 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:07:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:07:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:07:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:07:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:07:03 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET :///robots.txt>: Unsupported URL scheme '': no handler available for that scheme
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/10279>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/5359>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/6939>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/7326>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/5841>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/7476>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/3276>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/10076>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:04 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/10334>
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:04 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(2)%20a/jspui/handle/2011/7208>
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:04 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:07:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 11,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 11,
 'downloader/request_bytes': 4049,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 12823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 7, 4, 136112),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 "robotstxt/exception_count/<class 'scrapy.exceptions.NotSupported'>": 1,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 7, 2, 680154)}
2019-04-29 23:07:04 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:07:44 [scrapy.extensions.telnet] INFO: Telnet Password: d84499a76669d415
2019-04-29 23:07:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:07:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:07:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:07:44 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:07:44 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:07:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:07:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:07:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:07:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:07:45 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET :///robots.txt>: Unsupported URL scheme '': no handler available for that scheme
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/10279>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/5359>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/6939>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/7326>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/3276>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/5841>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/7476>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/10076>
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/10334>
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.scraper] ERROR: Error downloading <GET div%20table%20tr%20td:nth-child(3)/jspui/handle/2011/7208>
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 70, in download_request
    (scheme, self._notconfigured[scheme]))
scrapy.exceptions.NotSupported: Unsupported URL scheme '': no handler available for that scheme
2019-04-29 23:07:45 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:07:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 11,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 11,
 'downloader/request_bytes': 4009,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 12823,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 7, 45, 844170),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 11,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 "robotstxt/exception_count/<class 'scrapy.exceptions.NotSupported'>": 1,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 7, 44, 437111)}
2019-04-29 23:07:45 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:08:01 [scrapy.extensions.telnet] INFO: Telnet Password: f7021b97034757a0
2019-04-29 23:08:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:08:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:08:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:08:02 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:08:02 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:08:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:08:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:08:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:03 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:04 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:04 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:04 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:04 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:08:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 8, 4, 140117),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 8, 2, 255155)}
2019-04-29 23:08:04 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:08:24 [scrapy.extensions.telnet] INFO: Telnet Password: 39fd98de13328f0e
2019-04-29 23:08:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:08:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:08:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:08:24 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:08:24 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:08:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:08:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:08:24 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:26 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:26 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:26 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:08:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 8, 26, 68135),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 8, 24, 371154)}
2019-04-29 23:08:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:08:44 [scrapy.extensions.telnet] INFO: Telnet Password: f1ef48670a64eff4
2019-04-29 23:08:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:08:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:08:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:08:44 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:08:44 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:08:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:08:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:08:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:08:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:46 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:08:55 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:08:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:08:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 8, 55, 429168),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 8, 44, 952111)}
2019-04-29 23:08:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:09:00 [scrapy.extensions.telnet] INFO: Telnet Password: f45f4e834934e775
2019-04-29 23:09:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:09:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:09:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:09:01 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:09:01 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:09:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:09:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:09:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.scraper] ERROR: Error processing {'autor': None}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:09:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156170,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 9, 2, 972112),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 9, 1, 279153)}
2019-04-29 23:09:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:09:09 [scrapy.extensions.telnet] INFO: Telnet Password: 2c6470caa91e7a1a
2019-04-29 23:09:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:09:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:09:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:09:09 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:09:09 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:09:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:09:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:09:10 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:09:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:09:11 [scrapy.core.scraper] ERROR: Error processing {'autor': []}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:09:11 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:09:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 9, 11, 611188),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 9, 9, 908155)}
2019-04-29 23:09:11 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:10:09 [scrapy.extensions.telnet] INFO: Telnet Password: 5dd8fe872fce9687
2019-04-29 23:10:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:10:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:10:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:10:09 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:10:09 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:10:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:10:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:10:09 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').attrib['href']
KeyError: 'href'
2019-04-29 23:10:11 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:10:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 10, 11, 180172),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'spider_exceptions/KeyError': 10,
 'start_time': datetime.datetime(2019, 4, 30, 2, 10, 9, 462151)}
2019-04-29 23:10:11 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:10:54 [scrapy.extensions.telnet] INFO: Telnet Password: 009f36604ac6e056
2019-04-29 23:10:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:10:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:10:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:10:54 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:10:54 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:10:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:10:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:10:54 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 30, in extrair
    item['autor'] = response.css('div table tr td:nth-child(3) a').get(attrib['href'])
NameError: name 'attrib' is not defined
2019-04-29 23:10:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:10:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 10, 56, 530111),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'spider_exceptions/NameError': 10,
 'start_time': datetime.datetime(2019, 4, 30, 2, 10, 54, 745151)}
2019-04-29 23:10:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:12:53 [scrapy.extensions.telnet] INFO: Telnet Password: f24be52ff3f86fbf
2019-04-29 23:12:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:12:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:12:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:12:53 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:12:53 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:12:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:12:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:12:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:12:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:12:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:54 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:12:55 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:12:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:12:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 12, 55, 324170),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 12, 53, 559151)}
2019-04-29 23:12:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:13:15 [scrapy.extensions.telnet] INFO: Telnet Password: bae27c991f89c906
2019-04-29 23:13:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:13:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:13:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:13:15 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:13:15 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:13:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:13:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:13:15 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:16 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:17 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:25 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:26 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:13:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 13, 26, 1150),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 13, 15, 599150)}
2019-04-29 23:13:26 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:13:39 [scrapy.extensions.telnet] INFO: Telnet Password: 0844be198b397348
2019-04-29 23:13:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:13:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:13:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:13:39 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:13:39 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:13:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:13:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:13:39 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:13:40 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:41 [scrapy.core.scraper] ERROR: Error processing {}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:13:41 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:13:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156059,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 13, 41, 89113),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 13, 39, 328113)}
2019-04-29 23:13:41 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:14:49 [scrapy.extensions.telnet] INFO: Telnet Password: 6654f6b79ef590d2
2019-04-29 23:14:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:14:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:14:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:14:49 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:14:49 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:14:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:14:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:14:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:14:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 31, in extrair
    item['autor'] = RefAutor.css('a').attrib['href']
KeyError: 'href'
2019-04-29 23:14:54 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:14:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 14, 54, 637169),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'spider_exceptions/KeyError': 10,
 'start_time': datetime.datetime(2019, 4, 30, 2, 14, 49, 949112)}
2019-04-29 23:14:54 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:15:24 [scrapy.extensions.telnet] INFO: Telnet Password: 1f08f0cdf14d7634
2019-04-29 23:15:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:15:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:15:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:15:24 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:15:24 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:15:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:15:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:15:24 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:15:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:15:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:25 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:26 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:15:44 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:15:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:15:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156083,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 15, 44, 110156),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 15, 24, 657154)}
2019-04-29 23:15:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:21:08 [scrapy.extensions.telnet] INFO: Telnet Password: e676d7d7c3fd2ee8
2019-04-29 23:21:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:21:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:21:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:21:09 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:21:09 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:21:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:21:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:21:09 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:10 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:10 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:10 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:10 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:11 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:21:11 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:21:11 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:21:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 21, 11, 419164),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 21, 9, 221110)}
2019-04-29 23:21:11 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:22:46 [scrapy.extensions.telnet] INFO: Telnet Password: 1339751e181fb80f
2019-04-29 23:22:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:22:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:22:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:22:46 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:22:46 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:22:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:22:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:22:48 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:22:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:22:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:22:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156150,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 22, 50, 622152),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 22, 46, 435151)}
2019-04-29 23:22:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:26:34 [scrapy.extensions.telnet] INFO: Telnet Password: dd927ba4e969ef92
2019-04-29 23:26:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:26:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:26:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:26:34 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:26:34 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:26:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:26:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:26:34 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://repositorio.ufpa.br/robots.txt> (referer: None)
2019-04-29 23:26:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental> (referer: None)
2019-04-29 23:26:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10279> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:35 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/3276> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10076> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/10334> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7326> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7476> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/6939> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5841> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/7208> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:36 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Artigo+de+Peri%C3%B3dico'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://repositorio.ufpa.br/jspui/handle/2011/5359> (referer: http://repositorio.ufpa.br/jspui/simple-search?query=saude+mental)
2019-04-29 23:26:54 [scrapy.core.scraper] ERROR: Error processing {'autor': '/jspui/browse?type=type&value=Disserta%C3%A7%C3%A3o'}
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\pipelines.py", line 11, in process_item
    print(item['div'])
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 'div'
2019-04-29 23:26:54 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:26:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4177,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 156176,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 26, 54, 88150),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 10,
 'log_count/INFO': 9,
 'request_depth_max': 1,
 'response_received_count': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2019, 4, 30, 2, 26, 34, 310159)}
2019-04-29 23:26:54 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:35:56 [scrapy.extensions.telnet] INFO: Telnet Password: 543c7c0d18e15a1f
2019-04-29 23:35:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:35:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:35:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:35:56 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:35:56 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:35:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:35:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:35:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:35:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:35:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 35, 57, 442121),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 35, 56, 723157)}
2019-04-29 23:35:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:36:13 [scrapy.extensions.telnet] INFO: Telnet Password: 901faec5574c531f
2019-04-29 23:36:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:36:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:36:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:36:14 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:36:14 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:36:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:36:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:36:14 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:36:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 33, in parse
    links1 = response.css('ul.ds-artifact-list li tr td:nth-child(2):text').get()
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\scrapy\http\response\text.py", line 122, in css
    return self.selector.css(query)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\parsel\selector.py", line 262, in css
    return self.xpath(self._css2xpath(query))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\parsel\selector.py", line 265, in _css2xpath
    return self._csstranslator.css_to_xpath(query)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\parsel\csstranslator.py", line 109, in css_to_xpath
    return super(HTMLTranslator, self).css_to_xpath(css, prefix)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 192, in css_to_xpath
    for selector in parse(css))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 192, in <genexpr>
    for selector in parse(css))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 219, in selector_to_xpath
    xpath = self.xpath(tree)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 254, in xpath
    return method(parsed_selector)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 264, in xpath_combinedselector
    self.xpath(combined.subselector))
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 254, in xpath
    return method(parsed_selector)
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\cssselect\xpath.py", line 291, in xpath_pseudo
    "The pseudo-class :%s is unknown" % pseudo.ident)
cssselect.xpath.ExpressionError: The pseudo-class :text is unknown
2019-04-29 23:36:15 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:36:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 36, 15, 158130),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ExpressionError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 36, 14, 192120)}
2019-04-29 23:36:15 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:36:20 [scrapy.extensions.telnet] INFO: Telnet Password: ef5f696d9cf583dc
2019-04-29 23:36:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:36:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:36:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:36:21 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:36:21 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:36:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:36:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:36:21 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:36:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:36:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 36, 22, 39176),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 36, 21, 301161)}
2019-04-29 23:36:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:39:26 [scrapy.extensions.telnet] INFO: Telnet Password: 9b9c88130427e933
2019-04-29 23:39:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:39:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:39:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:39:26 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:39:26 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:39:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:39:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:39:27 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:39:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:39:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 39, 27, 673163),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 39, 26, 923161)}
2019-04-29 23:39:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:40:01 [scrapy.extensions.telnet] INFO: Telnet Password: 04e406292cb59ccb
2019-04-29 23:40:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:40:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:40:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:40:01 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:40:01 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:40:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:40:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:40:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:40:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:40:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:40:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 40, 2, 238119),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 40, 1, 419162)}
2019-04-29 23:40:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:43:27 [scrapy.extensions.telnet] INFO: Telnet Password: 2495ba07c9b67381
2019-04-29 23:43:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:43:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:43:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:43:28 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:43:28 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:43:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:43:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:43:28 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:43:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:43:29 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:43:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 43, 29, 50119),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 43, 28, 304161)}
2019-04-29 23:43:29 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:49:14 [scrapy.extensions.telnet] INFO: Telnet Password: 94f51b1f870cc7e0
2019-04-29 23:49:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:49:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:49:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:49:14 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:49:14 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:49:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:49:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:49:14 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:49:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 36, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:49:15 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:49:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 49, 15, 390156),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 49, 14, 463155)}
2019-04-29 23:49:15 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:49:27 [scrapy.extensions.telnet] INFO: Telnet Password: ada9150d643cf4cf
2019-04-29 23:49:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:49:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:49:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:49:28 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:49:28 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:49:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:49:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:49:28 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:49:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:49:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 36, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:49:28 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:49:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 49, 28, 856176),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 49, 28, 57118)}
2019-04-29 23:49:28 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:51:55 [scrapy.extensions.telnet] INFO: Telnet Password: 0de9a7284d4c8adf
2019-04-29 23:51:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:51:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:51:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:51:55 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:51:55 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:51:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:51:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:51:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:51:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:51:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:51:56 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:51:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 51, 56, 619121),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 51, 55, 816123)}
2019-04-29 23:51:56 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:52:15 [scrapy.extensions.telnet] INFO: Telnet Password: f48a4f593055ffb9
2019-04-29 23:52:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:52:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:52:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:52:15 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:52:15 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:52:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:52:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:52:15 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:52:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:52:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:52:16 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:52:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 52, 16, 267118),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 52, 15, 328159)}
2019-04-29 23:52:16 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:53:00 [scrapy.extensions.telnet] INFO: Telnet Password: dfb0828220e3ed46
2019-04-29 23:53:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:53:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:53:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:53:01 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:53:01 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:53:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:53:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:53:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:53:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:53:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:53:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:53:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 53, 2, 84178),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 53, 1, 148161)}
2019-04-29 23:53:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:53:05 [scrapy.extensions.telnet] INFO: Telnet Password: 40aa62245d225e3d
2019-04-29 23:53:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:53:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:53:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:53:06 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:53:06 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:53:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:53:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:53:06 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:53:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:53:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:53:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:53:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 53, 7, 63180),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 53, 6, 238119)}
2019-04-29 23:53:07 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:53:19 [scrapy.extensions.telnet] INFO: Telnet Password: be68876ae7705827
2019-04-29 23:53:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:53:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:53:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:53:19 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:53:19 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:53:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:53:19 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:53:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:53:20 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:53:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 53, 20, 181180),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 53, 19, 371159)}
2019-04-29 23:53:20 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:54:56 [scrapy.extensions.telnet] INFO: Telnet Password: 7f808bd461f0750a
2019-04-29 23:54:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:54:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:54:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:54:56 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:54:56 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:54:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:54:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:54:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:54:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:54:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:54:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:54:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 54, 57, 526184),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 54, 56, 689159)}
2019-04-29 23:54:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:57:56 [scrapy.extensions.telnet] INFO: Telnet Password: f3d1530b3c93985e
2019-04-29 23:57:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:57:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:57:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:57:57 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:57:57 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:57:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:57:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:57:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:57:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:57:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
Traceback (most recent call last):
  File "C:\Users\felip\AppData\Local\Programs\Python\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "F:\Scrapy\FelipePazin\FelipePazin\spiders\spiders.py", line 38, in parse
    for link in links1:
TypeError: 'NoneType' object is not iterable
2019-04-29 23:57:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:57:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 57, 57, 907121),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 57, 57, 95146)}
2019-04-29 23:57:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:58:37 [scrapy.extensions.telnet] INFO: Telnet Password: a1da52fa23df71ff
2019-04-29 23:58:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:58:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:58:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:58:37 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:58:37 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:58:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:58:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:58:37 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:58:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:58:38 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:58:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 58, 38, 240119),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 58, 37, 424161)}
2019-04-29 23:58:38 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:58:57 [scrapy.extensions.telnet] INFO: Telnet Password: 427108a1080700c2
2019-04-29 23:58:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:58:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:58:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:58:57 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:58:57 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:58:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:58:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:58:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:58:58 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:58:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 58, 58, 403161),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 58, 57, 519159)}
2019-04-29 23:58:58 [scrapy.core.engine] INFO: Spider closed (finished)
2019-04-29 23:59:11 [scrapy.extensions.telnet] INFO: Telnet Password: 49a6aa98a6b4795e
2019-04-29 23:59:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-04-29 23:59:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-04-29 23:59:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-04-29 23:59:11 [scrapy.middleware] INFO: Enabled item pipelines:
['FelipePazin.pipelines.FelipePazinPipeline']
2019-04-29 23:59:11 [scrapy.core.engine] INFO: Spider opened
2019-04-29 23:59:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-04-29 23:59:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-04-29 23:59:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://www.bibliotecadigital.ufmg.br/robots.txt> (referer: None)
2019-04-29 23:59:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.bibliotecadigital.ufmg.br/dspace/search?query=saude+mental&submit=Go> (referer: None)
2019-04-29 23:59:12 [scrapy.core.engine] INFO: Closing spider (finished)
2019-04-29 23:59:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 508,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 52248,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 4, 30, 2, 59, 12, 408146),
 'log_count/DEBUG': 2,
 'log_count/INFO': 9,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 4, 30, 2, 59, 11, 719158)}
2019-04-29 23:59:12 [scrapy.core.engine] INFO: Spider closed (finished)
